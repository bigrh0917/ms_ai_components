"""
æµ‹è¯• Elasticsearch æ£€ç´¢æœåŠ¡
"""
import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(project_root))

from app.services.search_service import search_service
from app.services.embedding_service import embedding_service
from app.clients.elasticsearch_client import es_client
from app.clients.db_client import db_client
from app.core.config import settings
from app.utils.logger import setup_logging, get_logger
from app.models.file import FileUpload, DocumentVector
from app.models.user import User
from sqlalchemy import select

# åˆå§‹åŒ–æ—¥å¿—
setup_logging()
logger = get_logger(__name__)


async def test_index_creation():
    """æµ‹è¯•ç´¢å¼•åˆ›å»º"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 1: Elasticsearch ç´¢å¼•åˆ›å»º")
    print("=" * 60)
    
    try:
        # ç¡®ä¿ç´¢å¼•å­˜åœ¨
        success = await search_service.ensure_index_exists()
        
        if success:
            print("âœ… ç´¢å¼•åˆ›å»º/éªŒè¯æˆåŠŸ")
            
            # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨
            exists = await es_client.index_exists(search_service.INDEX_NAME)
            print(f"   ç´¢å¼•åç§°: {search_service.INDEX_NAME}")
            print(f"   ç´¢å¼•å­˜åœ¨: {exists}")
            
            # è·å–ç´¢å¼•mapping
            try:
                mapping = await es_client.client.indices.get_mapping(index=search_service.INDEX_NAME)
                print(f"   ç´¢å¼•mapping: å·²é…ç½®")
                
                # æ£€æŸ¥å‘é‡å­—æ®µ
                properties = mapping[search_service.INDEX_NAME]["mappings"]["properties"]
                if "vector" in properties:
                    vector_config = properties["vector"]
                    print(f"   å‘é‡å­—æ®µé…ç½®:")
                    print(f"     - ç»´åº¦: {vector_config.get('dims', 'N/A')}")
                    print(f"     - ç±»å‹: {vector_config.get('type', 'N/A')}")
                    print(f"     - ç›¸ä¼¼åº¦ç®—æ³•: {vector_config.get('similarity', 'N/A')}")
                
            except Exception as e:
                print(f"   âš ï¸  è·å–mappingå¤±è´¥: {e}")
            
            return True
        else:
            print("âŒ ç´¢å¼•åˆ›å»ºå¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ ç´¢å¼•åˆ›å»ºå¼‚å¸¸: {e}")
        logger.error(f"ç´¢å¼•åˆ›å»ºå¼‚å¸¸: {e}", exc_info=True)
        return False


async def test_index_document():
    """æµ‹è¯•ç´¢å¼•æ–‡æ¡£ï¼ˆæ·»åŠ æµ‹è¯•æ•°æ®ï¼‰"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 2: ç´¢å¼•æ–‡æ¡£åˆ° Elasticsearch")
    print("=" * 60)
    
    try:
        # ç¡®ä¿ç´¢å¼•å­˜åœ¨
        await search_service.ensure_index_exists()
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        # æ³¨æ„ï¼šuser_id=1 çš„æ–‡æ¡£ï¼ˆå±äºå½“å‰æµ‹è¯•ç”¨æˆ·ï¼‰
        #       user_id=999 çš„æ–‡æ¡£ï¼ˆä¸å±äºå½“å‰æµ‹è¯•ç”¨æˆ·ï¼Œç”¨äºæµ‹è¯•æƒé™è¿‡æ»¤ï¼‰
        test_docs = [
            {
                "file_md5": "test_file_001",
                "chunk_id": 0,
                "text_content": "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚",
                "vector": None,  # éœ€è¦å‘é‡åŒ–
                "user_id": 1,
                "org_tag": "DEFAULT",
                "is_public": True,
                "file_name": "test_ai_intro.txt",
                "model_version": settings.OPENAI_EMBEDDING_MODEL
            },
            {
                "file_md5": "test_file_001",
                "chunk_id": 1,
                "text_content": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ å’Œæ”¹è¿›ã€‚",
                "vector": None,
                "user_id": 1,
                "org_tag": "DEFAULT",
                "is_public": True,
                "file_name": "test_ai_intro.txt",
                "model_version": settings.OPENAI_EMBEDDING_MODEL
            },
            {
                "file_md5": "test_file_002",
                "chunk_id": 0,
                "text_content": "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶ç®€æ´çš„è¯­æ³•å’Œå¼ºå¤§çš„åŠŸèƒ½è€Œé—»åã€‚",
                "vector": None,
                "user_id": 1,
                "org_tag": "DEFAULT",
                "is_public": True,
                "file_name": "test_python.txt",
                "model_version": settings.OPENAI_EMBEDDING_MODEL
            },
            # æ·»åŠ ä¸å±äº user_id=1 çš„æ–‡æ¡£ï¼ˆç”¨äºæµ‹è¯•æƒé™è¿‡æ»¤ï¼‰
            {
                "file_md5": "test_file_other_user",
                "chunk_id": 0,
                "text_content": "è¿™æ˜¯å¦ä¸€ä¸ªç”¨æˆ·ï¼ˆuser_id=999ï¼‰çš„ç§æœ‰æ–‡æ¡£ï¼ŒåŒ…å«æ•æ„Ÿä¿¡æ¯ï¼Œä¸åº”è¯¥è¢« user_id=1 æ£€ç´¢åˆ°ã€‚",
                "vector": None,
                "user_id": 999,  # ä¸åŒçš„ç”¨æˆ·ID
                "org_tag": "PRIVATE_TAG",  # ä¸åŒçš„æ ‡ç­¾ï¼Œä¸”ä¸æ˜¯DEFAULT
                "is_public": False,  # ä¸æ˜¯å…¬å¼€çš„
                "file_name": "test_other_user_private.txt",
                "model_version": settings.OPENAI_EMBEDDING_MODEL
            },
            {
                "file_md5": "test_file_other_user_public",
                "chunk_id": 0,
                "text_content": "è¿™æ˜¯å¦ä¸€ä¸ªç”¨æˆ·ï¼ˆuser_id=999ï¼‰çš„å…¬å¼€æ–‡æ¡£ï¼Œè™½ç„¶ä¸å±äºuser_id=1ï¼Œä½†æ˜¯å…¬å¼€çš„ï¼Œåº”è¯¥å¯ä»¥è¢«æ£€ç´¢åˆ°ã€‚",
                "vector": None,
                "user_id": 999,  # ä¸åŒçš„ç”¨æˆ·ID
                "org_tag": "OTHER_TAG",  # ä¸åŒçš„æ ‡ç­¾
                "is_public": True,  # ä½†æ˜¯å…¬å¼€çš„
                "file_name": "test_other_user_public.txt",
                "model_version": settings.OPENAI_EMBEDDING_MODEL
            }
        ]
        
        print(f"å‡†å¤‡ç´¢å¼• {len(test_docs)} ä¸ªæµ‹è¯•æ–‡æ¡£...")
        print(f"  - user_id=1 çš„æ–‡æ¡£: 3 ä¸ª")
        print(f"  - user_id=999 çš„ç§æœ‰æ–‡æ¡£: 1 ä¸ªï¼ˆä¸åº”è¯¥è¢« user_id=1 æ£€ç´¢åˆ°ï¼‰")
        print(f"  - user_id=999 çš„å…¬å¼€æ–‡æ¡£: 1 ä¸ªï¼ˆå¯ä»¥è¢«æ£€ç´¢åˆ°ï¼Œå› ä¸ºæ˜¯å…¬å¼€çš„ï¼‰")
        
        # å‘é‡åŒ–æ–‡æœ¬
        texts = [doc["text_content"] for doc in test_docs]
        vectors = await embedding_service.embed_batch(texts)
        
        # æ›´æ–°æ–‡æ¡£å‘é‡
        for i, vector in enumerate(vectors):
            if vector:
                test_docs[i]["vector"] = vector
        
        # ç´¢å¼•æ–‡æ¡£
        success_count = 0
        for doc in test_docs:
            if doc["vector"]:
                doc_id = f"{doc['file_md5']}_{doc['chunk_id']}"
                result = await es_client.index_document(
                    index=search_service.INDEX_NAME,
                    document=doc,
                    doc_id=doc_id
                )
                if result:
                    success_count += 1
                    print(f"  âœ… ç´¢å¼•æ–‡æ¡£: {doc_id} ({doc['file_name']})")
                else:
                    print(f"  âŒ ç´¢å¼•å¤±è´¥: {doc_id}")
            else:
                print(f"  âš ï¸  è·³è¿‡ï¼ˆå‘é‡åŒ–å¤±è´¥ï¼‰: {doc['file_md5']}_{doc['chunk_id']}")
        
        # åˆ·æ–°ç´¢å¼•
        await es_client.refresh_index(search_service.INDEX_NAME)
        print(f"\nâœ… ç´¢å¼•å®Œæˆ: {success_count}/{len(test_docs)}")
        
        return success_count > 0
        
    except Exception as e:
        print(f"âŒ ç´¢å¼•æ–‡æ¡£å¼‚å¸¸: {e}")
        logger.error(f"ç´¢å¼•æ–‡æ¡£å¼‚å¸¸: {e}", exc_info=True)
        return False


async def test_hybrid_search():
    """æµ‹è¯•æ··åˆæ£€ç´¢ï¼ˆåŒ…å«æƒé™è¿‡æ»¤éªŒè¯ï¼‰"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 3: æ··åˆæ£€ç´¢ï¼ˆå‘é‡ + å…¨æ–‡ï¼‰+ æƒé™è¿‡æ»¤éªŒè¯")
    print("=" * 60)
    print("\nè¯´æ˜ï¼š")
    print("  - å½“å‰æµ‹è¯•ç”¨æˆ·: user_id=1")
    print("  - åº”è¯¥æ£€ç´¢åˆ°: user_id=1 çš„æ–‡æ¡£ + å…¬å¼€æ–‡æ¡£")
    print("  - ä¸åº”è¯¥æ£€ç´¢åˆ°: user_id=999 çš„ç§æœ‰æ–‡æ¡£")
    print("-" * 60)
    
    try:
        # ç¡®ä¿ç´¢å¼•å­˜åœ¨å¹¶æœ‰æ•°æ®
        await search_service.ensure_index_exists()
        
        # æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
            "Pythonç¼–ç¨‹è¯­è¨€",
            "æœºå™¨å­¦ä¹ ",
            "æ•æ„Ÿä¿¡æ¯",  # è¿™ä¸ªæŸ¥è¯¢åº”è¯¥åŒ¹é…åˆ° user_id=999 çš„ç§æœ‰æ–‡æ¡£ï¼Œä½†è¯¥æ–‡æ¡£ä¸åº”è¯¥è¢«æ£€ç´¢åˆ°
        ]
        
        all_tests_passed = True
        for query in test_queries:
            print(f"\næŸ¥è¯¢: {query}")
            print("-" * 60)
            
            # å‘é‡åŒ–æŸ¥è¯¢
            query_vector = await embedding_service.embed_query(query)
            if not query_vector:
                print(f"  âŒ æŸ¥è¯¢å‘é‡åŒ–å¤±è´¥")
                continue
            
            print(f"  æŸ¥è¯¢å‘é‡ç»´åº¦: {len(query_vector)}")
            
            # æ„å»ºæƒé™è¿‡æ»¤ï¼ˆæ¨¡æ‹Ÿ user_id=1 çš„æƒé™ï¼‰
            # ç”¨æˆ·å¯ä»¥è®¿é—®ï¼š1. è‡ªå·±ä¸Šä¼ çš„æ–‡æ¡£ 2. å…¬å¼€çš„æ–‡æ¡£ 3. DEFAULTæ ‡ç­¾çš„æ–‡æ¡£
            permission_filters = [
                {"term": {"user_id": 1}},  # ç”¨æˆ·è‡ªå·±çš„æ–‡æ¡£
                {"term": {"is_public": True}},  # å…¬å¼€æ–‡æ¡£
                {"term": {"org_tag": "DEFAULT"}}  # DEFAULTæ ‡ç­¾çš„æ–‡æ¡£
            ]
            
            # æ„å»ºæ··åˆæŸ¥è¯¢
            es_query = search_service.build_hybrid_query(
                query_vector=query_vector,
                query_text=query,
                permission_filters=permission_filters
            )
            
            # æ‰§è¡Œæœç´¢
            result = await es_client.search(
                index=search_service.INDEX_NAME,
                query=es_query["query"],
                size=10  # å¢åŠ è¿”å›æ•°é‡ï¼Œç¡®ä¿èƒ½çœ‹åˆ°æ‰€æœ‰ç»“æœ
            )
            
            if result:
                hits = result.get("hits", {}).get("hits", [])
                total = result.get("hits", {}).get("total", {}).get("value", 0)
                
                print(f"  æ‰¾åˆ° {total} ä¸ªç»“æœï¼ˆæ˜¾ç¤ºå‰ {len(hits)} ä¸ªï¼‰:")
                
                # éªŒè¯æƒé™è¿‡æ»¤æ˜¯å¦ç”Ÿæ•ˆ
                found_unauthorized = False
                for i, hit in enumerate(hits, 1):
                    source = hit.get("_source", {})
                    score = hit.get("_score", 0.0)
                    user_id = source.get('user_id')
                    is_public = source.get('is_public', False)
                    org_tag = source.get('org_tag', '')
                    file_name = source.get('file_name', 'N/A')
                    
                    # æ£€æŸ¥æƒé™ï¼šå¦‚æœä¸æ˜¯ user_id=1ï¼Œä¸”ä¸æ˜¯å…¬å¼€çš„ï¼Œä¸”ä¸æ˜¯DEFAULTæ ‡ç­¾ï¼Œåˆ™ä¸åº”è¯¥è¢«æ£€ç´¢åˆ°
                    is_authorized = (
                        user_id == 1 or 
                        is_public or 
                        org_tag == "DEFAULT"
                    )
                    
                    if not is_authorized:
                        found_unauthorized = True
                        print(f"\n  âš ï¸  ç»“æœ {i} [æƒé™éªŒè¯å¤±è´¥]:")
                    else:
                        print(f"\n  âœ… ç»“æœ {i}:")
                    
                    print(f"    æ–‡ä»¶: {file_name}")
                    print(f"    ç”¨æˆ·ID: {user_id}")
                    print(f"    æ˜¯å¦å…¬å¼€: {is_public}")
                    print(f"    ç»„ç»‡æ ‡ç­¾: {org_tag}")
                    print(f"    åˆ†å—ID: {source.get('chunk_id', 'N/A')}")
                    print(f"    åˆ†æ•°: {score:.4f}")
                    print(f"    å†…å®¹: {source.get('text_content', '')[:50]}...")
                
                # ç»Ÿè®¡ç»“æœ
                user_own_docs = sum(1 for hit in hits if hit.get("_source", {}).get('user_id') == 1)
                public_docs = sum(1 for hit in hits if hit.get("_source", {}).get('is_public', False))
                other_user_private_docs = sum(1 for hit in hits 
                    if hit.get("_source", {}).get('user_id') == 999 
                    and not hit.get("_source", {}).get('is_public', False)
                    and hit.get("_source", {}).get('org_tag') != 'DEFAULT')
                
                print(f"\n  ğŸ“Š æ£€ç´¢ç»“æœç»Ÿè®¡:")
                print(f"     - ç”¨æˆ·è‡ªå·±çš„æ–‡æ¡£ (user_id=1): {user_own_docs} ä¸ª")
                print(f"     - å…¬å¼€æ–‡æ¡£: {public_docs} ä¸ª")
                print(f"     - å…¶ä»–ç”¨æˆ·çš„ç§æœ‰æ–‡æ¡£: {other_user_private_docs} ä¸ª")
                
                if found_unauthorized:
                    print(f"\n  âŒ æƒé™è¿‡æ»¤å¤±è´¥ï¼šæ£€ç´¢åˆ°äº†ä¸åº”è¯¥è¢«è®¿é—®çš„æ–‡æ¡£ï¼")
                    print(f"     é¢„æœŸ: ä¸åº”è¯¥æ£€ç´¢åˆ° user_id=999 çš„ç§æœ‰æ–‡æ¡£")
                    all_tests_passed = False
                else:
                    print(f"\n  âœ… æƒé™è¿‡æ»¤æ­£å¸¸ï¼šæ‰€æœ‰æ£€ç´¢åˆ°çš„æ–‡æ¡£éƒ½æ˜¯ç”¨æˆ·æœ‰æƒé™è®¿é—®çš„")
            else:
                print(f"  âš ï¸  æœªæ‰¾åˆ°ç»“æœ")
        
        if not all_tests_passed:
            print(f"\nâš ï¸  éƒ¨åˆ†æŸ¥è¯¢çš„æƒé™è¿‡æ»¤æµ‹è¯•å¤±è´¥")
        
        return all_tests_passed
        
    except Exception as e:
        print(f"âŒ æ··åˆæ£€ç´¢å¼‚å¸¸: {e}")
        logger.error(f"æ··åˆæ£€ç´¢å¼‚å¸¸: {e}", exc_info=True)
        return False


async def test_permission_filter():
    """æµ‹è¯•æƒé™è¿‡æ»¤"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 4: æƒé™è¿‡æ»¤")
    print("=" * 60)
    
    try:
        # æ„å»ºä¸åŒçš„æƒé™è¿‡æ»¤æ¡ä»¶
        test_cases = [
            {
                "name": "å…¬å¼€æ–‡æ¡£",
                "filters": [{"term": {"is_public": True}}]
            },
            {
                "name": "DEFAULTæ ‡ç­¾",
                "filters": [{"term": {"org_tag": "DEFAULT"}}]
            },
            {
                "name": "ç”¨æˆ·è‡ªå·±çš„æ–‡æ¡£",
                "filters": [{"term": {"user_id": 1}}]
            },
            {
                "name": "ç»„åˆæ¡ä»¶ï¼ˆå…¬å¼€ OR DEFAULTï¼‰",
                "filters": [
                    {
                        "bool": {
                            "should": [
                                {"term": {"is_public": True}},
                                {"term": {"org_tag": "DEFAULT"}}
                            ],
                            "minimum_should_match": 1
                        }
                    }
                ]
            }
        ]
        
        for case in test_cases:
            print(f"\næµ‹è¯•: {case['name']}")
            
            # æ„å»ºæŸ¥è¯¢
            query = {
                "query": {
                    "bool": {
                        "must": [{"match_all": {}}],
                        "filter": case["filters"]
                    }
                },
                "size": 5
            }
            
            result = await es_client.search(
                index=search_service.INDEX_NAME,
                query=query["query"],
                size=5
            )
            
            if result:
                total = result.get("hits", {}).get("total", {}).get("value", 0)
                print(f"  æ‰¾åˆ° {total} ä¸ªæ–‡æ¡£")
            else:
                print(f"  âš ï¸  æŸ¥è¯¢å¤±è´¥")
        
        return True
        
    except Exception as e:
        print(f"âŒ æƒé™è¿‡æ»¤æµ‹è¯•å¼‚å¸¸: {e}")
        logger.error(f"æƒé™è¿‡æ»¤æµ‹è¯•å¼‚å¸¸: {e}", exc_info=True)
        return False


async def cleanup_test_data():
    """æ¸…ç†æµ‹è¯•æ•°æ®"""
    print("\n" + "=" * 60)
    print("æ¸…ç†æµ‹è¯•æ•°æ®")
    print("=" * 60)
    
    try:
        test_doc_ids = [
            "test_file_001_0",
            "test_file_001_1",
            "test_file_002_0",
            "test_file_other_user_0",  # æ·»åŠ å…¶ä»–ç”¨æˆ·çš„æ–‡æ¡£ID
            "test_file_other_user_public_0"  # æ·»åŠ å…¶ä»–ç”¨æˆ·çš„å…¬å¼€æ–‡æ¡£ID
        ]
        
        deleted_count = 0
        for doc_id in test_doc_ids:
            try:
                success = await es_client.delete_document(
                    index=search_service.INDEX_NAME,
                    doc_id=doc_id
                )
                if success:
                    deleted_count += 1
                    print(f"  âœ… åˆ é™¤: {doc_id}")
            except Exception as e:
                print(f"  âš ï¸  åˆ é™¤å¤±è´¥ {doc_id}: {e}")
        
        await es_client.refresh_index(search_service.INDEX_NAME)
        print(f"\nâœ… æ¸…ç†å®Œæˆ: åˆ é™¤äº† {deleted_count}/{len(test_doc_ids)} ä¸ªæµ‹è¯•æ–‡æ¡£")
        
    except Exception as e:
        print(f"âš ï¸  æ¸…ç†å¼‚å¸¸: {e}")


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "=" * 60)
    print("Elasticsearch æ£€ç´¢æœåŠ¡æµ‹è¯•")
    print("=" * 60)
    print(f"Elasticsearch Host: {settings.ES_HOST}")
    print(f"ç´¢å¼•åç§°: {search_service.INDEX_NAME}")
    print(f"å‘é‡ç»´åº¦: {search_service.VECTOR_DIMENSIONS}")
    
    # æ£€æŸ¥é…ç½®
    if not settings.OPENAI_API_KEY or settings.OPENAI_API_KEY == "your-openai-api-key-here":
        print("\nâŒ é”™è¯¯: è¯·å…ˆåœ¨ .env æ–‡ä»¶ä¸­é…ç½® OPENAI_API_KEY")
        return
    
    try:
        # è¿æ¥æ•°æ®åº“å’ŒES
        db_client.connect()
        await es_client.connect()
        
        results = []
        
        # è¿è¡Œæµ‹è¯•
        results.append(("ç´¢å¼•åˆ›å»º", await test_index_creation()))
        results.append(("ç´¢å¼•æ–‡æ¡£", await test_index_document()))
        results.append(("æ··åˆæ£€ç´¢", await test_hybrid_search()))
        results.append(("æƒé™è¿‡æ»¤", await test_permission_filter()))
        
        # æ¸…ç†æµ‹è¯•æ•°æ®
        await cleanup_test_data()
        
        # æ±‡æ€»ç»“æœ
        print("\n" + "=" * 60)
        print("æµ‹è¯•ç»“æœæ±‡æ€»")
        print("=" * 60)
        for test_name, result in results:
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            print(f"{test_name}: {status}")
        
        passed = sum(1 for _, result in results if result)
        total = len(results)
        print(f"\næ€»è®¡: {passed}/{total} é€šè¿‡")
        
        if passed == total:
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        else:
            print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œè¿æ¥")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¼‚å¸¸: {e}")
        logger.error(f"æµ‹è¯•å¼‚å¸¸: {e}", exc_info=True)
    finally:
        # å…³é—­è¿æ¥
        await es_client.close()
        db_client.close()


if __name__ == "__main__":
    asyncio.run(main())

